# 🧪 Guide d'exécution des tests - MCP Task Management Server

Ce guide explique comment exécuter les tests pour le serveur MCP de gestion des tâches basé sur l'architecture Domain-Driven Design (DDD).

## 📊 Vue d'ensemble des tests

### Test complete project

How to run full test
└── pwd for see where i am
│   ├── if i am not on cursor_agent directory: `cd /home/<username>/agentic-project/cursor_agent`
│   └── if i am on cursor_agent: `uv run pytest tests/dev/ -v --tb=short --full-trace`
└── clear all not important files generated by test when test finish

### Structure des tests

```
cursor_agent/tests/
├── quick/                    # ✅ Tests rapides (24 tests, < 1 min)
│   ├── test_basic_api.py     # API de base et structures
│   ├── test_imports.py       # Imports et dépendances
│   └── test_server_start.py  # Démarrage serveur
├── dev/
│   ├── unit/                 # ✅ Tests unitaires (158 tests)
│   │   ├── test_auto_rule_generation.py    # 16 tests - Génération auto-règles
│   │   ├── test_cursor_rules_tools.py      # 12 tests - Outils Cursor
│   │   ├── test_yaml_role_system.py        # 21 tests - Système YAML
│   │   ├── test_domain_entities.py         # 22 tests - Entités domaine
│   │   ├── test_value_objects.py           # 26 tests - Objets valeur
│   │   ├── test_business_rules.py          # 15 tests - Règles métier
│   │   ├── test_ddd_boundaries.py          # 15 tests - Limites DDD
│   │   ├── test_mcp_tools.py               # 9 tests - Outils MCP
│   │   └── test_mcp_tools_simple.py        # 6 tests - Outils MCP simples
│   └── integration/          # ✅ Tests d'intégration (14 tests)
│       ├── test_auto_rule_integration.py   # 7 tests - Intégration auto-règles
│       ├── test_mcp_integration.py         # 5 tests - Intégration MCP
│       └── test_role_integration.py        # 4 tests - Intégration rôles
└── conftest.py              # Configuration pytest
```

## 🚀 Commandes d'exécution avec `uv`

`uv` est utilisé pour exécuter les tests. Il détecte et utilise automatiquement l'environnement virtuel du projet (`.venv`), donc l'activation manuelle avec `source .venv/bin/activate` n'est plus nécessaire.

Assurez-vous d'être dans le bon répertoire :
```bash
pwd
cd /home/<username>/agentic-project/cursor_agent
```

### 1. **Exécuter tous les tests**
```bash
# Commande complète (recommandée)
cd /home/<username>/agentic-project/cursor_agent && uv run pytest tests/ -v

# Ou si déjà dans le répertoire
uv run pytest tests/ -v
```

### 2. **Tests par catégorie**

#### Tests rapides (développement) - 24 tests
```bash
# Tests rapides pour vérification (< 1 minute)
uv run pytest tests/quick/ -v
```

#### Tests unitaires - 130+ tests
```bash
# Tests unitaires seulement
uv run pytest tests/dev/unit/ -v
```

#### Tests d'intégration - 16 tests
```bash
# Tests d'intégration seulement  
uv run pytest tests/dev/integration/ -v
```

### 3. **Tests par markers**
```bash
# Tests MCP
uv run pytest -m mcp -v

# Tests DDD
uv run pytest -m ddd -v

# Tests YAML
uv run pytest -m yaml -v

# Tests de génération automatique de règles
uv run pytest -m auto_rule -v

# Tests des règles métier
uv run pytest -m business_rules -v

# Tests d'architecture
uv run pytest -m architecture -v
```

### 4. **Tests avec couverture de code**
```bash
# Avec rapport de couverture HTML
uv run pytest tests/ --cov=src --cov-report=html

# Couverture simplifiée en terminal
uv run pytest tests/ --cov=src --cov-report=term-missing

# Couverture avec seuil minimum
uv run pytest tests/ --cov=src --cov-fail-under=80
```

### 5. **Tests spécifiques**
```bash
# Un seul fichier de test
uv run pytest tests/dev/unit/test_cursor_rules_tools.py -v

# Une seule classe de test
uv run pytest tests/dev/unit/test_cursor_rules_tools.py::TestCursorRulesTools -v

# Un seul test
uv run pytest tests/dev/unit/test_cursor_rules_tools.py::TestCursorRulesTools::test_update_auto_rule_success -v
```

### 6. **Tests en mode debug**
```bash
# Mode verbose avec logs
uv run pytest tests/ -v -s --log-cli-level=DEBUG

# Arrêter au premier échec
uv run pytest tests/ -x

# Mode silencieux (moins de sortie)
uv run pytest tests/ -q

# Afficher les 10 tests les plus lents
uv run pytest tests/ --durations=10
```

## 📋 Configuration pytest

Le fichier `pytest.ini` contient la configuration suivante :

### Markers personnalisés
- `quick`: Tests rapides pour développement (< 60 secondes)
- `unit`: Tests unitaires (1-2 minutes)
- `integration`: Tests d'intégration (2-3 minutes)
- `slow`: Tests lents (à éviter en développement)
- `mcp`: Tests spécifiques au serveur MCP
- `ddd`: Tests de conception pilotée par le domaine
- `yaml`: Tests de configuration YAML
- `auto_rule`: Tests de génération automatique de règles
- `domain`: Tests de la couche domaine
- `business_rules`: Tests des règles métier
- `architecture`: Tests de validation d'architecture

### Options par défaut
- Couverture de code activée (`--cov=src`)
- Rapport de couverture avec lignes manquantes
- Seuil de couverture minimum : 80%
- Logs CLI activés avec niveau INFO

## 🎯 Recommandations d'usage

### **Développement quotidien**
```bash
# Tests rapides pour vérification
uv run pytest tests/quick/ -v
```

### **Avant commit**
```bash
# Tests complets
uv run pytest tests/ -v
```

### **Développement de nouvelles fonctionnalités**
```bash
# Tests spécifiques à votre zone de travail
uv run pytest tests/dev/unit/test_cursor_rules_tools.py -v
```

### **CI/CD**
```bash
# Tests avec couverture et rapport XML
uv run pytest tests/ --cov=src --cov-report=xml --cov-fail-under=80
```

### **Debug d'un test spécifique**
```bash
# Mode debug avec breakpoints
uv run pytest tests/dev/unit/test_cursor_rules_tools.py::TestCursorRulesTools::test_update_auto_rule_success -v -s --pdb
```

## 🔧 Résolution des problèmes

### Avertissements
Les 78 avertissements concernent des markers personnalisés non enregistrés. Ils sont normaux et n'affectent pas l'exécution des tests.

### Dépendances manquantes
Si vous rencontrez des erreurs d'import, installez les dépendances de test :
```bash
uv pip install -e ".[test]"
```

## 📊 Couverture de test

### Couches testées
- **Domain Layer** : Entités, objets valeur, événements domaine (63 tests)
- **Application Layer** : Services application, DTOs, cas d'usage (25 tests)
- **Infrastructure Layer** : Repositories, services externes (30 tests)
- **Interface Layer** : Outils MCP, serveur (64 tests)

### Fonctionnalités testées
- **✅ Gestion des tâches** : CRUD complet, validation, transitions d'état
- **✅ Système de rôles YAML** : Chargement, validation, intégration
- **✅ Génération auto-règles** : Déclenchement, contenu, fallback
- **✅ Outils Cursor** : Mise à jour, validation, gestion
- **✅ Architecture DDD** : Limites, dépendances, patterns
- **✅ Serveur MCP** : Démarrage, outils, intégration

## 🏆 Métriques de qualité

- **Taux de réussite** : 100% (182/182) ✅
- **Couverture de code** : > 80%
- **Tests par composant** : Chaque module testé
- **Tests d'intégration** : Flux complets validés
- **Performance** : Tests rapides < 1 seconde

## 🔄 Workflow de test

### 1. **Développement local**
```bash
# Tests rapides pendant le développement
uv run pytest tests/quick/ -v

# Tests spécifiques à votre fonctionnalité
uv run pytest tests/dev/unit/test_[votre_module].py -v
```

### 2. **Validation avant commit**
```bash
# Tests complets
uv run pytest tests/ -v

# Vérification de la couverture
uv run pytest tests/ --cov=src --cov-report=term-missing
```

### 3. **Pipeline CI/CD**
```bash
# Tests avec rapport pour CI
uv run pytest tests/ --cov=src --cov-report=xml --junitxml=test-results.xml
```

## 📝 Ajout de nouveaux tests

### Structure recommandée
```python
"""
Unit Test: [Description de la fonctionnalité]
Task [ID] - [Nom de la tâche]
Duration: [Temps estimé]
"""

import pytest
import sys
import os

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'src'))

class Test[NomDuModule]:
    """Test cases for [Description du module]."""
    
    @pytest.mark.unit
    @pytest.mark.[category]
    def test_[nom_du_test](self):
        """Test [description spécifique]."""
        # Arrange
        # Act  
        # Assert
        pass
```

### Markers à utiliser
- Toujours inclure `@pytest.mark.unit` ou `@pytest.mark.integration`
- Ajouter des markers spécifiques : `@pytest.mark.mcp`, `@pytest.mark.ddd`, etc.
- Utiliser des noms de test descriptifs

---

**Dernière mise à jour** : 2025-01-17  
**Version du projet** : MCP Task Management Server v1.0  
**Architecture** : Domain-Driven Design avec FastMCP 2.0 